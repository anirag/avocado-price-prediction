{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Details\n",
    "\n",
    ">  Assume your avocado data collection is on a 1 month delay. When predicting the price of an avocado at time x, you can only use historical data from up until 1 month prior to x)\n",
    "\n",
    "> **Setup** : We need to bui;d dataset from the given to perform this type of modeling. A model should be trained on records which uses features based on historical data one month prior to current time. In order to create that dataset, from the original dataset, grouped by region and type shift all the numerical columns by 5 records(5 weeks, approx month). Now each record has feature values only of a month prior and at any point in time only information prior to month is being used\n",
    "\n",
    ">**Features**: Model(XGBoost) conventional and organic separartely, \n",
    ">> * Label encode region as numerical variable. \n",
    ">> * Add lags of price values from month prior\n",
    ">> * Add long term and short term moving average to capture trend\n",
    ">> * Add month  and day variable from date to capture seasonality\n",
    "\n",
    ">**Evaluation**: Time series cross validation, split data into train and test using the date variable. Use RMSE to evaluate. Used gridsearch to get the parameter values for the xgboost model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:31:47.345932Z",
     "start_time": "2019-11-07T21:31:47.339212Z"
    }
   },
   "outputs": [],
   "source": [
    "# import packages for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting libraries\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "import janitor\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Lasso\n",
    "from sklearn.model_selection import GroupKFold, TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_squared_log_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:31:47.549200Z",
     "start_time": "2019-11-07T21:31:47.546492Z"
    }
   },
   "outputs": [],
   "source": [
    "avocado_type = 'conventional'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:31:47.899229Z",
     "start_time": "2019-11-07T21:31:47.867035Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"avocado.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:31:48.083174Z",
     "start_time": "2019-11-07T21:31:48.059649Z"
    }
   },
   "outputs": [],
   "source": [
    "# Removing index column\n",
    "df.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "\n",
    "# Removing records with TotalUS region, assuming it is nust the average of all other regions\n",
    "df = df.loc[df.region!='TotalUS'].reset_index(drop=True)\n",
    "\n",
    "# Making date to datetime and sorting chrinologically\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df = df.sort_values(['region','Date'])\n",
    "df = df.clean_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:31:48.259904Z",
     "start_time": "2019-11-07T21:31:48.250936Z"
    }
   },
   "outputs": [],
   "source": [
    "df.date.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:31:48.461362Z",
     "start_time": "2019-11-07T21:31:48.450734Z"
    }
   },
   "outputs": [],
   "source": [
    "future_dates = ['2018-04-01','2018-04-08','2018-04-15','2018-04-22']\n",
    "regions = list(set(df.region))\n",
    "types = list(set(df.type))\n",
    "from itertools import product\n",
    "future_df = pd.DataFrame(list(product(future_dates, regions, types)), columns=['date', 'region', 'type'])\n",
    "future_df.date = pd.to_datetime(future_df.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:31:48.658943Z",
     "start_time": "2019-11-07T21:31:48.650506Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.append(future_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Creation - One month Lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:31:50.861611Z",
     "start_time": "2019-11-07T21:31:49.082303Z"
    }
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for avocado_type in types:\n",
    "    for region in regions:\n",
    "        #print(region)\n",
    "        temp = df.loc[(df.region==region)&(df.type==avocado_type)].sort_values('date').reset_index(drop=True)\n",
    "        for col in ['total_volume','4046','4225','4770','total_bags','small_bags','large_bags','xlarge_bags','averageprice']:\n",
    "            temp[f'one_month_lag_{col}'] = temp[col].shift(5)\n",
    "            if col!='averageprice':\n",
    "                temp.drop(col,axis=1,inplace=True)\n",
    "        temp = temp.loc[temp.one_month_lag_total_volume.notnull()].reset_index(drop=True)\n",
    "        #print(temp.shape)\n",
    "        df_list.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:31:50.902801Z",
     "start_time": "2019-11-07T21:31:50.864060Z"
    }
   },
   "outputs": [],
   "source": [
    "final_train = pd.concat(df_list)\n",
    "final_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:31:50.911039Z",
     "start_time": "2019-11-07T21:31:50.905345Z"
    }
   },
   "outputs": [],
   "source": [
    "pickle.dump(final_train,open('data_with_one_month_lag.p','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:31:50.933961Z",
     "start_time": "2019-11-07T21:31:50.912972Z"
    }
   },
   "outputs": [],
   "source": [
    "final_train = final_train.loc[final_train.type==avocado_type]\n",
    "final_train = final_train.sort_values(['date']).reset_index(drop=True)\n",
    "final_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:31:51.429953Z",
     "start_time": "2019-11-07T21:31:51.298609Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding month and day variable to visualize seasonal patterns\n",
    "final_train['month']=final_train['date'].apply(lambda x:x.month)\n",
    "final_train['day']=final_train['date'].apply(lambda x:x.day)\n",
    "\n",
    "for lag in range(1,4):\n",
    "    final_train[f'one_month_lag_lag_{lag}'] = final_train.groupby(['region','type'])['one_month_lag_averageprice'].shift(lag)\n",
    "    \n",
    "final_train['long_term_moving_average'] = final_train.groupby(['region','type'])['one_month_lag_averageprice'].transform(lambda x: x.rolling(window=52,min_periods=1).mean())\n",
    "final_train['short_term_moving_average'] = final_train.groupby(['region','type'])['one_month_lag_averageprice'].transform(lambda x: x.rolling(window=12,min_periods=1).mean())\n",
    "final_train['is_SMA_greater'] = (final_train['short_term_moving_average'] > final_train['long_term_moving_average'])\n",
    "#for lag in range(1,11):\n",
    "    #final_train[f'volume_lag_{lag}'] = final_train.groupby(['region','type'])['one_month_lag_total_volume'].shift(lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:31:51.925574Z",
     "start_time": "2019-11-07T21:31:51.915391Z"
    }
   },
   "outputs": [],
   "source": [
    "test = final_train.loc[(final_train.date>='2018-01-01')&(final_train.date<'2018-04-01')].reset_index(drop=True)\n",
    "train = final_train.loc[final_train.date<'2018-01-01'].reset_index(drop=True)\n",
    "future = final_train.loc[final_train.date>='2018-04-01'].reset_index(drop=True)\n",
    "#train = final_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:31:52.466312Z",
     "start_time": "2019-11-07T21:31:52.459275Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocessing(df, train=True):\n",
    "    \n",
    "    num_columns = ['one_month_lag_total_volume','one_month_lag_4046','one_month_lag_4225',\n",
    "                   'one_month_lag_4770','one_month_lag_total_bags','one_month_lag_small_bags', \n",
    "                   'one_month_lag_large_bags', 'one_month_lag_xlarge_bags']\n",
    "\n",
    "    if train:\n",
    "        sc = StandardScaler()\n",
    "        scaled_columns = sc.fit_transform(df[num_columns])\n",
    "        scaled_df = pd.DataFrame(scaled_columns)\n",
    "        scaled_df.columns = num_columns\n",
    "        df = df.drop(num_columns,axis=1).join(scaled_df)\n",
    "        pickle.dump(sc,open('one_month_lag_scaler.p','wb'))\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        label_encoding = le.fit_transform(df['region'])\n",
    "        df['region'] = label_encoding\n",
    "        pickle.dump(le,open('region_label_encoding.p','wb'))\n",
    "        \n",
    "    else:\n",
    "        sc = pickle.load(open('one_month_lag_scaler.p','rb'))\n",
    "        scaled_columns = sc.transform(df[num_columns])\n",
    "        scaled_df = pd.DataFrame(scaled_columns)\n",
    "        scaled_df.columns = num_columns\n",
    "        df = df.drop(num_columns,axis=1).join(scaled_df)\n",
    "        \n",
    "        le = pickle.load(open('region_label_encoding.p','rb'))\n",
    "        df['region'] = le.transform(df['region'])\n",
    "        \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:31:53.225336Z",
     "start_time": "2019-11-07T21:31:53.204544Z"
    }
   },
   "outputs": [],
   "source": [
    "train = preprocessing(train,train=True)\n",
    "test = preprocessing(test,train=False)\n",
    "future = preprocessing(future,train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model fitting and Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:31:55.200580Z",
     "start_time": "2019-11-07T21:31:55.194783Z"
    }
   },
   "outputs": [],
   "source": [
    "y = train['averageprice']\n",
    "date = train['date']\n",
    "X = train.drop(['date','averageprice','type'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:31:55.481355Z",
     "start_time": "2019-11-07T21:31:55.478437Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "'learning_rate':0.05, \n",
    "'n_estimators': 10000,\n",
    "'colsample_bytree': 0.8, \n",
    "'gamma': 0.3, 'max_depth': 7, \n",
    "'min_child_weight': 4, \n",
    "'subsample': 0.6\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:32:04.844849Z",
     "start_time": "2019-11-07T21:31:55.811030Z"
    }
   },
   "outputs": [],
   "source": [
    "folds = TimeSeriesSplit(n_splits=5)\n",
    "predictions=[]\n",
    "for i, (train_index,test_index) in enumerate(folds.split(X)):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    date_train, date_test = date[train_index], date[test_index]\n",
    "    eval_set =  [(X_test, y_test)]\n",
    "    model = XGBRegressor(**params)\n",
    "    model.fit(X_train,y_train,eval_metric=\"rmse\", eval_set=eval_set, early_stopping_rounds=100,verbose=200)\n",
    "    pred=model.predict(X_test)\n",
    "    print(f\"Validation RMSE for fold {i}: {round(np.sqrt(mean_squared_error(y_test,pred)),3)}\\n\")\n",
    "    predictions.append(pd.DataFrame({'fold':'fold_'+str(i),'date': date_test,'region':X_test.region,'actual_price':y_test, 'predicted_price':pred}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:32:04.853038Z",
     "start_time": "2019-11-07T21:32:04.847513Z"
    }
   },
   "outputs": [],
   "source": [
    "all_preds = pd.concat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:32:04.860406Z",
     "start_time": "2019-11-07T21:32:04.854907Z"
    }
   },
   "outputs": [],
   "source": [
    "le = pickle.load(open('region_label_encoding.p','rb'))\n",
    "all_preds.region = le.inverse_transform(all_preds.region)\n",
    "train.region = le.inverse_transform(train.region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T20:16:16.544706Z",
     "start_time": "2019-11-07T20:16:16.540856Z"
    }
   },
   "source": [
    "# Visualization of Prediction - Holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:32:04.865062Z",
     "start_time": "2019-11-07T21:32:04.862687Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualize prediction for a region\n",
    "region = 'Denver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:32:05.292273Z",
     "start_time": "2019-11-07T21:32:04.868298Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting the time series from train and test dataframes\n",
    "train_dates = train.loc[(train.region==region), 'date']\n",
    "test_dates = all_preds.loc[(all_preds.fold=='fold_4')&(all_preds.region==region), 'date']\n",
    "train_values = train.loc[(train.region==region), 'averageprice']\n",
    "test_values = all_preds.loc[(all_preds.fold=='fold_4')&(all_preds.region==region), 'actual_price']\n",
    "test_predictions = all_preds.loc[(all_preds.fold=='fold_4')&(all_preds.region==region), 'predicted_price']\n",
    "\n",
    "# Getting the error\n",
    "rmse = round(np.sqrt(mean_squared_error(test_values,test_predictions)),3)\n",
    "# Plotting the predictions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 8));\n",
    "ax.plot(train_dates,train_values, color='blue', label='Training Data');\n",
    "ax.plot(test_dates, test_predictions, color='green', marker='o',label='Predicted Price');\n",
    "\n",
    "ax.plot(test_dates, test_values, color='red', label='Actual Price');\n",
    "ax.set_title(f'{region} region -  Avocado Prices Prediction - {avocado_type} \\nRMSE: {rmse}');\n",
    "ax.set_xlabel('Dates');\n",
    "ax.set_ylabel('Prices');\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:32:07.630499Z",
     "start_time": "2019-11-07T21:32:05.294603Z"
    }
   },
   "outputs": [],
   "source": [
    "# Predicting for test set and visualization\n",
    "params = {\n",
    "'learning_rate':0.05, \n",
    "'n_estimators': 200,\n",
    "'colsample_bytree': 0.8, \n",
    "'gamma': 0.3, 'max_depth': 7, \n",
    "'min_child_weight': 4, \n",
    "'subsample': 0.6\n",
    "}\n",
    "model = XGBRegressor(**params)\n",
    "model.fit(X,y)\n",
    "test_preds = model.predict(test[X.columns])\n",
    "test['predicted_price'] = test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:06:05.288975Z",
     "start_time": "2019-11-07T21:06:05.286857Z"
    }
   },
   "source": [
    "# Visulaization of prediction - Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:32:07.636773Z",
     "start_time": "2019-11-07T21:32:07.632475Z"
    }
   },
   "outputs": [],
   "source": [
    "X.region = le.inverse_transform(X.region)\n",
    "test.region = le.inverse_transform(test.region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:32:08.071061Z",
     "start_time": "2019-11-07T21:32:07.638715Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting the time series from train and test dataframes\n",
    "train_dates = train.loc[(train.region==region), 'date']\n",
    "test_dates = test.loc[(test.region==region), 'date']\n",
    "train_values = train.loc[(train.region==region), 'averageprice']\n",
    "test_values = test.loc[(test.region==region), 'averageprice']\n",
    "test_predictions = test.loc[(test.region==region), 'predicted_price']\n",
    "\n",
    "# Getting the error\n",
    "rmse = round(np.sqrt(mean_squared_error(test_values,test_predictions)),3)\n",
    "# Plotting the predictions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 8));\n",
    "ax.plot(train_dates,train_values, color='blue', label='Training Data');\n",
    "ax.plot(test_dates, test_predictions, color='green', marker='o',label='Predicted Price');\n",
    "\n",
    "ax.plot(test_dates, test_values, color='red', label='Actual Price');\n",
    "ax.set_title(f'{region} region -  Avocado Prices Prediction - {avocado_type} \\nRMSE: {rmse}');\n",
    "ax.set_xlabel('Dates');\n",
    "ax.set_ylabel('Prices');\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:32:08.476576Z",
     "start_time": "2019-11-07T21:32:08.073032Z"
    }
   },
   "outputs": [],
   "source": [
    "importance = model.get_booster().get_score(importance_type= 'gain')\n",
    "importance_df = pd.DataFrame(list(importance.items()), columns = ['feature','importance'])\n",
    "importance_df = importance_df.sort_values('importance',ascending=False)\n",
    "plt.figure(figsize=(8,10));\n",
    "sns.barplot(importance_df.importance,importance_df.feature);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ** The important features turned out to be the lag values and moving average of price. The volume and bag counts are in the top 10 features but theie effects are rather small. This suggests that classic time series models would be better in predicting the price.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:15:51.035473Z",
     "start_time": "2019-11-07T21:15:51.032719Z"
    }
   },
   "source": [
    "# Shapley values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:32:09.053372Z",
     "start_time": "2019-11-07T21:32:08.478634Z"
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "import warnings\n",
    "explainer = shap.TreeExplainer(model)\n",
    "expected_value = explainer.expected_value\n",
    "if isinstance(expected_value, list):\n",
    "    expected_value = expected_value[1]\n",
    "print(f\"Explainer expected value: {expected_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:32:19.098694Z",
     "start_time": "2019-11-07T21:32:09.055382Z"
    }
   },
   "outputs": [],
   "source": [
    "test.region = le.transform(test.region)\n",
    "X_features = test[X.columns]\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    shap_values = explainer.shap_values(X_features)\n",
    "    shap_interaction_values = explainer.shap_interaction_values(X_features)\n",
    "if isinstance(shap_interaction_values, list):\n",
    "    shap_interaction_values = shap_interaction_values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:32:20.913304Z",
     "start_time": "2019-11-07T21:32:19.100927Z"
    }
   },
   "outputs": [],
   "source": [
    "shap.decision_plot(expected_value, shap_values, X_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ** Shapley values analysis also shows that time related variables are more important for the model in predicting the prices, especially the lag values**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:32:40.938375Z",
     "start_time": "2019-11-07T21:32:40.930496Z"
    }
   },
   "outputs": [],
   "source": [
    "future_preds = model.predict(future[X.columns])\n",
    "future['predicted_price'] = future_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:36:27.831419Z",
     "start_time": "2019-11-07T21:36:27.826297Z"
    }
   },
   "outputs": [],
   "source": [
    "test.region = le.inverse_transform(test.region)\n",
    "future.region = le.inverse_transform(future.region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:36:28.904064Z",
     "start_time": "2019-11-07T21:36:28.514115Z"
    }
   },
   "outputs": [],
   "source": [
    "# Getting the time series from train and test dataframes\n",
    "train_dates = final_train.loc[(final_train.region==region), 'date']\n",
    "future_dates = future.loc[(future.region==region), 'date']\n",
    "train_values = final_train.loc[(final_train.region==region), 'averageprice']\n",
    "future_values = future.loc[(future.region==region), 'predicted_price']\n",
    "\n",
    "# Getting the error\n",
    "rmse = 0#round(np.sqrt(mean_squared_error(test_values,test_predictions)),3)\n",
    "# Plotting the predictions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 8));\n",
    "ax.plot(train_dates,train_values, color='blue', label='Training Data');\n",
    "ax.plot(future_dates, future_values, color='green', marker='o',label='Future Price');\n",
    "\n",
    "ax.set_title(f'{region} region -  Avocado Prices Prediction - {avocado_type} \\nRMSE: {rmse}');\n",
    "ax.set_xlabel('Dates');\n",
    "ax.set_ylabel('Prices');\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-07T21:38:01.865538Z",
     "start_time": "2019-11-07T21:38:01.854608Z"
    }
   },
   "outputs": [],
   "source": [
    "future.loc[(future.region==region), ['date','region','type','predicted_price']]"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
